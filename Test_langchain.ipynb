{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe37963-1af6-44fc-a841-8e462443f5e6",
   "metadata": {},
   "source": [
    "## Expert Knowledge Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2779af-84ef-4227-9e9e-6eaf0df87e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\Job-Aware-RAG-Agent\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports libary\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c85082-e417-4708-9efe-81a5d55d1424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare AI model gpt-4o-mini is the most lowest cost model\n",
    "\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee78efcb-60fe-449e-a944-40bab26261af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0652c2-3d76-40c7-8313-9dc1895155a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['association_rule_learning', 'clustering', 'decision_tree', 'dimensionality_reduction', 'gradient_boosting', 'knn', 'linear_regression', 'logistic_regression', 'machine_learning', 'machine_learning_overview', 'naive_bayes', 'random_forest', 'regression_classification', 'reinforcement_learning ', 'supervised_learning', 'svm', 'unsupervised_learning'])\n"
     ]
    }
   ],
   "source": [
    "# Test matching documents\n",
    "\n",
    "context = {}\n",
    "\n",
    "documents = glob.glob(\"knowledge_base/Machine_Learning/*\")\n",
    "\n",
    "for document in documents:\n",
    "    name = document.split(os.sep)[-1][:-3]\n",
    "    doc = \"\"\n",
    "    with open(document, \"r\", encoding=\"utf-8\") as f:\n",
    "        doc = f.read()\n",
    "    context[name]=doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aba46a57-d973-4195-8fe3-70fc60687192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['association_rule_learning', 'clustering', 'decision_tree', 'dimensionality_reduction', 'gradient_boosting', 'knn', 'linear_regression', 'logistic_regression', 'machine_learning', 'machine_learning_overview', 'naive_bayes', 'random_forest', 'regression_classification', 'reinforcement_learning ', 'supervised_learning', 'svm', 'unsupervised_learning'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "129c7d1e-0094-4479-9459-f9360b95f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an expert in AI/ML career guidance. You must answer strictly based on the context provided from the database.\n",
    "If the context does not contain the necessary information, or if the answer cannot be derived directly from the context,\n",
    "you must respond: \"I do not have information in the database to answer this question.\"\n",
    "\n",
    "Rules:\n",
    "- Do not invent, guess, or hallucinate.\n",
    "- Do not rely on prior knowledge outside the provided context.\n",
    "- Provide brief, accurate answers only.\n",
    "- If the context is empty or irrelevant, say you don't have the data.\n",
    "- All answers must be in Vietnamese.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d40e390b-c110-42d5-8d80-daf3295b9862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_context(message):\n",
    "    relevant_context = []\n",
    "    for context_title, context_details in context.items():\n",
    "        if context_title.lower() in message.lower():\n",
    "            relevant_context.append(context_details)\n",
    "    return relevant_context          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d126cfcb-e85c-4dd9-837e-9d2b8436d4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['---\\ntitle: \"Decision Tree\"\\ndescription: \"Thuật toán Decision Tree trong Machine Learning.\"\\ntags: [\"Machine Learning\", \"Decision Tree\"]\\n---\\n\\n# Decision Tree\\n\\n## 1. Khái niệm\\n\\nDecision Tree là thuật toán thuộc nhóm **Supervised Learning**, dùng cho cả **Classification** và **Regression**. Mô hình hoạt động bằng cách chia dữ liệu thành các nhánh dựa trên điều kiện, tạo thành cấu trúc giống cây gồm **node**, **branch**, và **leaf**.\\n\\n---\\n\\n## 2. Cấu trúc cây quyết định\\n\\n* **Root Node**: điểm bắt đầu, chứa toàn bộ dữ liệu.\\n* **Internal Node**: nút kiểm tra điều kiện (feature).\\n* **Leaf Node**: nút kết luận → class label hoặc giá trị dự đoán.\\n* **Branch**: đường nối thể hiện lựa chọn theo điều kiện.\\n\\n---\\n\\n## 3. Cách hoạt động\\n\\n1. Chọn feature tốt nhất để chia dữ liệu.\\n2. Tạo một node với điều kiện rẽ nhánh.\\n3. Lặp lại cho từng nhánh đến khi đạt điều kiện dừng.\\n4. Node cuối trở thành leaf node.\\n\\n---\\n\\n## 4. Tiêu chí chọn feature (Split Criteria)\\n\\n### Đối với Classification\\n\\n* **Gini Impurity**\\n* **Entropy / Information Gain**\\n\\n### Đối với Regression\\n\\n* **MSE (Mean Squared Error)**\\n* **MAE (Mean Absolute Error)**\\n\\n---\\n\\n## 5. Ưu điểm\\n\\n* Dễ hiểu, trực quan.\\n* Không cần chuẩn hóa dữ liệu.\\n* Xử lý được dữ liệu dạng số và dạng phân loại.\\n* Hoạt động tốt khi quan hệ phi tuyến.\\n\\n---\\n\\n## 6. Nhược điểm\\n\\n* Dễ overfitting nếu không cắt tỉa (pruning).\\n* Nhạy với nhiễu và outlier.\\n* Thay đổi nhỏ trong dữ liệu có thể làm thay đổi cấu trúc cây.\\n\\n---\\n\\n## 7. Kỹ thuật cải thiện\\n\\n* **Pruning (Cắt tỉa)**: giảm độ sâu cây để tránh overfitting.\\n* **Max Depth**: giới hạn chiều cao cây.\\n* **Min Samples Split / Leaf**: yêu cầu số mẫu tối thiểu để split.\\n* **Feature Importance**: đánh giá độ quan trọng của từng feature.\\n\\n---\\n\\n## 8. Ứng dụng thực tế\\n\\n* Phân loại khách hàng.\\n* Chẩn đoán bệnh.\\n* Dự đoán rủi ro tín dụng.\\n* Hệ thống hỗ trợ ra quyết định.\\n\\n---\\n\\n## 9. Cách nhận biết khi nào dùng Decision Tree\\n\\nDùng khi:\\n\\n* Cần mô hình dễ diễn giải.\\n* Dữ liệu có quan hệ phi tuyến.\\n* Không muốn chuẩn hóa dữ liệu.\\n* Cần giải thích quyết định cho stakeholder.\\n\\n---\\n\\n## 10. Metric đánh giá\\n\\n### Đối với Classification\\n\\n* Accuracy\\n* Precision / Recall / F1\\n* Confusion Matrix\\n\\n### Đối với Regression\\n\\n* MSE / RMSE\\n* MAE\\n* R² Score\\n\\n---\\n\\n## 11. Cách trả lời phỏng vấn (chốt gọn)\\n\\n* Decision Tree là mô hình phân loại hoặc hồi quy dựa trên việc chia dữ liệu thành các nhánh theo điều kiện.\\n* Dễ hiểu, trực quan, nhưng dễ overfit nếu không cắt tỉa.\\n* Tiêu chí split: Gini / Entropy cho classification, MSE cho regression.\\n']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relevant_context(\"what about decision_tree?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7cef7f-f214-4bac-8217-3f9ab9ba1bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_context(message):\n",
    "    relevant_context = get_relevant_context(message)\n",
    "    if not relevant_context:\n",
    "        message += \"\\n\\n[CONTEXT NOT FOUND IN DATABASE]\"\n",
    "    \n",
    "    message += \"\\n\\nThe following additional context might be relevant in answering this question:\\n\\n\"\n",
    "    for relevant in relevant_context:\n",
    "            message += relevant + \"\\n\\n\"\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b36399c-440b-4049-9d39-68d208283c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what about decision tree?\n"
     ]
    }
   ],
   "source": [
    "print(add_context(\"what about decision tree?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "968e7bf2-e862-4679-a11f-6c1efb6ec8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    message = add_context(message)\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbcb659-13ce-47ab-8a5e-01b930494964",
   "metadata": {},
   "source": [
    "## Now we will bring this up in Gradio using the Chat interface -\n",
    "\n",
    "A quick and easy way to prototype a chat with an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3536590-85c7-4155-bd87-ae78a1467670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view = gr.ChatInterface(chat).launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48873d11-2fbd-4329-af27-46c781788561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
