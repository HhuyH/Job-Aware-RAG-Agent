{
  "education": "Van Hien University\n2021 - 2025\nBachelor of Software Engineering – Major in Computer Science\nGPA: 3.39 / 4.00",
  "profile": "learning. Experienced\nComputer Science graduate with\nin building AI-\nhands-on experience\npowered applications,\nfocusing on\nNLP, chatbot systems, and applied\nmachine\nin\ndeveloping backend services for AI\nfeatures, integrating LLM-based APIs,\nmulti-turn\nand\nconversational flows. Interested in AI\nengineering roles where AI models are\ntransformed into practical, real-world\nproducts.\ndesigning\nSeeking an AI Engineer Intern or\nJunior AI Engineer position where I\ncan apply my knowledge of machine\nlearning, NLP, and LLM-based\nsystems to build practical AI\nsolutions. I aim to grow through\nhands-on projects, mentorship, and\nreal-world system development while\ncontributing to AI-driven products\nwith measurable impact.\nPERSONAL INFORMATION\nPhone: 0901647655\nEmail hoanhuy12@gmail.com\nGithub: https://github.com/HhuyH\nLocation: Ho Chi Minh City, Vietnam",
  "skills": "Programming Languages:\n• Python, C++, SQL\nFrameworks & Technologies:\n• FastAPI, PyTorch, TensorFlow,\nPandas, NumPy, Redis, OpenCV,\nSelenium, Firebase\nAI / Machine Learning:\n• Machine Learning, Deep Learning,\nNLP\n• Conversational AI and multi-turn\ndialogue systems\n• Data preprocessing, model training\n& evaluation\n• Experience integrating LLM-based\nAPIs (OpenAI GPT API)\n• Familiar with basic Retrieval-\nAugmented Generation (RAG)\npipelines and LLM workflow\norchestration\nDatabase:\n• MySQL, SQL Server, Database\nDesign (ERD, DFD, Use Case).",
  "tools": "• GitHub, Jupyter Notebook, Google\nColab, SQL Server Management\nStudio, Android Studio, VS Code",
  "certifications": "• TOEIC 745 (Reading & Listening)",
  "identity": "LÊ NGUYỄN HOÀN HUY\nAI Engineer Intern / Fresher",
  "projects": "Project HealthCare – Chatbot — AI Developer\nDuration: May 19, 2025 – August 20, 2025\nDescription:\nAn intelligent healthcare chatbot that analyzes users’ initial symptoms to suggest whether they should visit a doctor. The system also supports consultation, appointment booking, health product recommendations, and natural language data queries. Additionally, I designed multi-turn dialogue flow with context tracking, similar to NPC-style conversation logic used in game bots.\nKey Features:\n• Symptom analysis: Asks follow-up questions and provides basic health advice.\n• Health consultation: Suggests improvement methods based on user conditions.\n• Appointment booking: Creates and confirms medical appointments through chat.\n• Product recommendation: Suggests suitable health products and devices; generates reports for doctors.\n• Admin tasks: Supports natural language queries on data such as products and orders.\nTechnologies: Python, FastAPI, GPT API, MySQL, Redis.\nProject Link: HealthCare Chatbot\n\nProject LLM-based Knowledge Assistant — Personal Project\n• Built a prototype Retrieval-Augmented Generation (RAG) system to answer domain-specific questions from custom documents.\n• Implemented document chunking, embeddings, vector search, and LLM response generation.\n• Explored LangChain to orchestrate retrieval and prompt pipelines.\nTechnologies: Python, LangChain, OpenAI API\nProject Link: LLM based Knowledge Assistant\n\nProject Alphabet – Sign Language Detection — Personal Project\nA system that recognizes American Sign Language (ASL) hand gestures (33 signs) using a Convolutional Neural Network (CNN) to support communication for the hearing-impaired community. Implemented real-time inference pipeline for continuous input streams.\nImplementation Process:\n• Migrated from Random Forest to CNN to improve performance.\n• Processed image data: removed backgrounds, cropped hand regions, applied data augmentation (rotation, background replacement).\n• Trained CNN model using TensorFlow/Keras, achieving ~94.6% accuracy across 33 gesture classes.\n• Configured a real-time demo with webcam integration (via Jupyter Notebook).\nTechnologies: Python, TensorFlow/Keras, OpenCV, Jupyter Notebook\nKey Result: Achieved approximately 94.62% accuracy across 33 ASL signs.\nFuture Vision:\n• Extend the system to recognize continuous sign language sequences and improve real-time usability.\nProject Link: AlphaBet Sign Language Detection"
}